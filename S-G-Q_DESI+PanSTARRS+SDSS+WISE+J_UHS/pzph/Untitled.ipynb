{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "481fc96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmalysheva/task/S-G-Q_DESI+PanSTARRS+SDSS+WISE+J_UHS/pzph/process_counterparts.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pzph1dot1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6ff3c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Not found PZPH1_DATA_PATH env variable. Using default path: /data/SRGz/pzph1/ =====\n"
     ]
    }
   ],
   "source": [
    "    try:\n",
    "        data_path = os.environ['PZPH1_DATA_PATH']\n",
    "        print(format_message(f'Found PZPH1_DATA_PATH env variable: {data_path}'))\n",
    "\n",
    "    except KeyError:\n",
    "        data_path = '/data/SRGz/pzph1/'\n",
    "        print(format_message(\n",
    "            f'Not found PZPH1_DATA_PATH env variable. Using default path: {data_path}'))\n",
    "\n",
    "    models_path = os.path.join(data_path, 'models')\n",
    "\n",
    "    models_series = {\n",
    "        'x0': {\n",
    "            'path': os.path.join(models_path, 'x0'),\n",
    "            'models': {\n",
    "                # 15: 'sdssdr16_QSO+GALAXY-train_QSO_XbalancedGALAXY-sdss_unwise-wo_3XMM_XXLN_S82X_LH-w_VHzQs-v2-asinhmag_features',  # there is not sdss wise in getaroundr\n",
    "                19: 'psdr2+wise_deacls8tr_QSO+GALAXY-train_QSO_XbalancedGALAXY-sdss_unwise-wo_3XMM_XXLN_S82X_LH-w_VHzQs-v2-asinhmag_features',\n",
    "                21: 'psdr2+all_deacls8tr_QSO+GALAXY-train_QSO_XbalancedGALAXY-sdss_unwise-wo_3XMM_XXLN_S82X_LH-w_VHzQs-v2-asinhmag_features',\n",
    "                22: 'deacls8tr_QSO+GALAXY-train_QSO_XbalancedGALAXY-sdss_unwise-wo_3XMM_XXLN_S82X_LH-w_VHzQs-v2-asinhmag_features',\n",
    "                35: 'sdssdr16+psdr2+all_deacls8tr_QSO+GALAXY-train_QSO_XbalancedGALAXY-sdss_unwise-wo_3XMM_XXLN_S82X_LH-w_VHzQs-v2-asinhmag_features',\n",
    "            },\n",
    "            'config': {\n",
    "                'perturb': 0,\n",
    "                'ebv_accounting': False,\n",
    "            },\n",
    "        },\n",
    "        'x0pswf': {\n",
    "            'path': os.path.join(models_path, 'x0'),\n",
    "            'models': {\n",
    "                19: 'psdr2+wise_deacls8tr_QSO+GALAXY-train_QSO_XbalancedGALAXY-sdss_unwise-wo_3XMM_XXLN_S82X_LH-w_VHzQs-v2-asinhmag_features',\n",
    "                21: 'psdr2+all_deacls8tr_QSO+GALAXY-train_QSO_XbalancedGALAXY-sdss_unwise-wo_3XMM_XXLN_S82X_LH-w_VHzQs-v2-asinhmag_features',\n",
    "                22: 'deacls8tr_QSO+GALAXY-train_QSO_XbalancedGALAXY-sdss_unwise-wo_3XMM_XXLN_S82X_LH-w_VHzQs-v2-asinhmag_features',\n",
    "                35: 'sdssdr16+psdr2+all_deacls8tr_QSO+GALAXY-train_QSO_XbalancedGALAXY-sdss_unwise-wo_3XMM_XXLN_S82X_LH-w_VHzQs-v2-asinhmag_features',\n",
    "            },\n",
    "            'config': {\n",
    "                'perturb': 0,\n",
    "                'ebv_accounting': False,\n",
    "                'use_wise_forced': True,\n",
    "            },\n",
    "        },\n",
    "        \"x1\": {\n",
    "            \"path\": os.path.join(models_path, 'x1'),\n",
    "            \"models\": {\n",
    "                \"18\": \"sdssdr16+wise_deacls8tr_QSO+GALAXY_20201212141009\",\n",
    "                \"19\": \"psdr2+wise_deacls8tr_QSO+GALAXY_20201212135046\",\n",
    "                \"20\": \"sdssdr16+all_deacls8tr_QSO+GALAXY_20201212143658\",\n",
    "                \"21\": \"psdr2+all_deacls8tr_QSO+GALAXY_20201212142333\",\n",
    "                \"22\": \"deacls8tr_QSO+GALAXY_20201212135641\",\n",
    "                \"34\": \"sdssdr16+psdr2+wise_deacls8tr_QSO+GALAXY_20201212131454\",\n",
    "                \"35\": \"sdssdr16+psdr2+all_deacls8tr_QSO+GALAXY_20201212133711\"\n",
    "            },\n",
    "            \"config\": {\n",
    "                \"perturb\": 8,\n",
    "                \"ebv_accounting\": True\n",
    "            }\n",
    "        },\n",
    "        \"x1a\": {\n",
    "            \"path\": os.path.join(models_path, 'x1'),\n",
    "            \"models\": {\n",
    "                \"18\": \"sdssdr16+wise_deacls8tr_QSO+GALAXY_20201212141009\",\n",
    "                \"19\": \"psdr2+wise_deacls8tr_QSO+GALAXY_20201212135046\",\n",
    "                \"20\": \"sdssdr16+all_deacls8tr_QSO+GALAXY_20201212143658\",\n",
    "                \"21\": \"psdr2+all_deacls8tr_QSO+GALAXY_20201212142333\",\n",
    "                \"22\": \"deacls8tr_QSO+GALAXY_20201212135641\",\n",
    "                \"34\": \"sdssdr16+psdr2+wise_deacls8tr_QSO+GALAXY_20201212131454\",\n",
    "                \"35\": \"sdssdr16+psdr2+all_deacls8tr_QSO+GALAXY_20201212133711\"\n",
    "            },\n",
    "            \"config\": {\n",
    "                \"perturb\": 0,\n",
    "                \"ebv_accounting\": True\n",
    "            }\n",
    "        },\n",
    "        'gal0': {\n",
    "            'path': os.path.join(models_path, 'gal0'),\n",
    "            'models': {\n",
    "                # 15: 'sdssdr16_GALAXY-train_GALAXY_million-sdss_unwise-wo_XXLN_S82X_LH-asinhmag_features',\n",
    "                19: 'psdr2+wise_deacls8tr_GALAXY-train_GALAXY_million-sdss_unwise-wo_XXLN_S82X_LH-asinhmag_features',\n",
    "                21: 'psdr2+all_deacls8tr_GALAXY-train_GALAXY_million-sdss_unwise-wo_XXLN_S82X_LH-asinhmag_features',\n",
    "                22: 'deacls8tr_GALAXY-train_GALAXY_million-sdss_unwise-wo_XXLN_S82X_LH-asinhmag_features',\n",
    "                # 34: 'sdssdr16+psdr2+wise_deacls8tr_QSO+GALAXY_20201004092833',\n",
    "                35: 'sdssdr16+psdr2+all_deacls8tr_GALAXY-train_GALAXY_million-sdss_unwise-wo_XXLN_S82X_LH-asinhmag_features',\n",
    "            },\n",
    "            'config': {\n",
    "                'perturb': 7,\n",
    "                'ebv_accounting': False,\n",
    "            }\n",
    "        },\n",
    "        'gal0pswf': {\n",
    "            'path': os.path.join(models_path, 'gal0'),\n",
    "            'models': {\n",
    "                # 15: 'sdssdr16_GALAXY-train_GALAXY_million-sdss_unwise-wo_XXLN_S82X_LH-asinhmag_features',\n",
    "                19: 'psdr2+wise_deacls8tr_GALAXY-train_GALAXY_million-sdss_unwise-wo_XXLN_S82X_LH-asinhmag_features',\n",
    "                21: 'psdr2+all_deacls8tr_GALAXY-train_GALAXY_million-sdss_unwise-wo_XXLN_S82X_LH-asinhmag_features',\n",
    "                22: 'deacls8tr_GALAXY-train_GALAXY_million-sdss_unwise-wo_XXLN_S82X_LH-asinhmag_features',\n",
    "                # 34: 'sdssdr16+psdr2+wise_deacls8tr_QSO+GALAXY_20201004092833',\n",
    "                35: 'sdssdr16+psdr2+all_deacls8tr_GALAXY-train_GALAXY_million-sdss_unwise-wo_XXLN_S82X_LH-asinhmag_features',\n",
    "            },\n",
    "            'config': {\n",
    "                'perturb': 7,\n",
    "                'ebv_accounting': False,\n",
    "                'use_wise_forced': True,\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538f819a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(assembledDataset=None, baseCatalog='ps', baseDecCol='decBest', baseRaCol='raBest', chunkSize=100000, coldStart=False, customModels=None, featuresTransformModule=None, featuresTransformName=None, getaroundrPath='/home/horungev/Catalogs/SRG/crossmatch/getaroundr.py', keepModelsInMemory=False, ls=None, lsOn=None, modelsIds=None, modelsSeries='x0pswf', njobs=24, outputDir='./output/', predictOn=None, primaryRadius=1.0, ps=None, psEdition='ps2fluxbest', psFluxesManually=False, psFluxesPath=None, psOn=None, sdss=None, sdssOn=None, secondaryRadius=1.0, useWiseForced=False, xrayCatalog='../data/3weak.gz_pkl', xrayDecCol='dec', xrayHealpixId=None, xrayRaCol='ra')\n"
     ]
    }
   ],
   "source": [
    "args = parse_cli_args(args= '--outputDir ./output/ \\\n",
    "--xrayCatalog ../data/3weak.gz_pkl --primaryRadius 1 \\\n",
    "--baseCatalog ps \\\n",
    "--njobs 24 \\\n",
    "--xrayRaCol ra --xrayDecCol dec \\\n",
    "--chunkSize 100000'.replace('\\n', '').split(' '))\n",
    "\n",
    "assert args.baseCatalog in ['ps', 'ls', 'sdss', 'gaiaedr3'], 'Other catalogs not implemented yet'\n",
    "assert args.psEdition in ['ps2oldfluxradecbest', 'ps2fluxbest']\n",
    "# assert not args.useWiseForced, 'Wise forced not implemented yet'\n",
    "\n",
    "if args.baseCatalog == \"ls\":\n",
    "    args.baseRaCol = 'ra'\n",
    "    args.baseDecCol = 'dec'\n",
    "elif args.baseCatalog == \"ps\":\n",
    "    args.baseRaCol = \"raBest\"\n",
    "    args.baseDecCol = \"decBest\"\n",
    "elif args.baseCatalog == \"sdss\":\n",
    "    args.baseRaCol = 'ra'\n",
    "    args.baseDecCol = 'dec'\n",
    "elif args.baseCatalog == \"gaiaedr3\":\n",
    "    args.baseRaCol = 'ra'\n",
    "    args.baseDecCol = 'dec'\n",
    "\n",
    "get_flags_data_path(check=True)\n",
    "print(args)\n",
    "\n",
    "if args.featuresTransformModule is not None and args.featuresTransformName is not None:\n",
    "    user_defined_features_transformation = _import_user_defined_features_transformation(\n",
    "        args.featuresTransformModule, args.featuresTransformName\n",
    "    )\n",
    "else:\n",
    "    user_defined_features_transformation = lambda x: x\n",
    "\n",
    "if args.coldStart:\n",
    "    try:\n",
    "        shutil.rmtree(os.path.join(args.outputDir))\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c3a6a6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.predictOn is NoneXZZZZZZZZzzzczxvhfdjtrkhhgkjfdgjdfgjfdgjdfgugdfhgughdufghjfghjg\n",
      "[('part-00000', 'xray')]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1065.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(args.outputDir, exist_ok=True)\n",
    "ps_objids = []\n",
    "buf_path = os.path.join(args.outputDir, 'buf')\n",
    "os.makedirs(buf_path, exist_ok=True)\n",
    "files2predict = []\n",
    "if args.predictOn is None:\n",
    "    print('args.predictOn is NoneXZZZZZZZZzzzczxvhfdjtrkhhgkjfdgjdfgjfdgjdfgugdfhgughdufghjfghjg')\n",
    "    catalog_kws = dict(\n",
    "        xray_data_path=args.xrayCatalog,\n",
    "        xray_radec_cols=(args.xrayRaCol, args.xrayDecCol),\n",
    "        base_catalog=args.baseCatalog,\n",
    "        base_radec_cols=(args.baseRaCol, args.baseDecCol),\n",
    "        sdss_path=args.sdss, ps_path=args.ps, ls_path=args.ls,\n",
    "        sdss_on=args.sdssOn, ps_on=args.psOn, ls_on=args.lsOn,\n",
    "        assembled_dataset_path=args.assembledDataset, output_dir=buf_path,\n",
    "        primary_radius=args.primaryRadius,\n",
    "        secondary_rasius=args.secondaryRadius, njobs=args.njobs,\n",
    "        getaroundr_path=args.getaroundrPath,\n",
    "        # cj_user_id=args.cjUserID, cj_password=args.cjPassword,\n",
    "        ps_fluxes_manually=args.psFluxesManually, ps_fluxes=None,\n",
    "        user_defined_features_transformation=user_defined_features_transformation,\n",
    "        panstarrs_catalog_to_use_cause_my_bullshit_code_and_noone_to_download_the_entire_panstarrs_properly_once_and_forall=args.psEdition,\n",
    "    )\n",
    "\n",
    "    data_path = os.path.join(args.outputDir, 'data')\n",
    "    data_written_file = os.path.join(data_path, \"DATA_WRITTEN_FILE.txt\")\n",
    "    if not os.path.isfile(data_written_file):\n",
    "        os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "        if args.xrayCatalog is not None:\n",
    "            if os.path.isdir(args.xrayCatalog):\n",
    "                iterator = [{'xray': file} for file in\n",
    "                            glob.glob(os.path.join(args.xrayCatalog, '*'))]\n",
    "            elif args.xrayHealpixId is not None:\n",
    "                iterator = list(\n",
    "                    split_data(xray=Catalog.read_table(args.xrayCatalog),\n",
    "                               xray_hp_id_col=args.xrayHealpixId)\n",
    "                )\n",
    "            else:\n",
    "                iterator = list(\n",
    "                    split_data(xray=Catalog.read_table(args.xrayCatalog),\n",
    "                               chunksize=args.chunkSize))\n",
    "\n",
    "        else:\n",
    "            iterator = list(split_data(sdss=Catalog.read_table(\n",
    "                args.sdss) if args.sdss is not None else None,\n",
    "                                       ps=Catalog.read_table(\n",
    "                                           args.ps) if args.ps is not None else None,\n",
    "                                       ls=Catalog.read_table(\n",
    "                                           args.ls) if args.ls is not None else None,\n",
    "                                       base_catalog=args.baseCatalog,\n",
    "                                       sdss_on=args.sdssOn,\n",
    "                                       ps_on=args.psOn, ls_on=args.lsOn,\n",
    "                                       chunksize=args.chunkSize))\n",
    "\n",
    "        for i, chunk in tqdm.tqdm(enumerate(iterator), total=len(iterator),\n",
    "                                  desc='Preparing data'):\n",
    "            if 'xray' in chunk and isinstance(chunk['xray'], str):\n",
    "                fname = os.path.basename(\n",
    "                    os.path.splitext(chunk['xray'])[0])\n",
    "            elif 'xray' in chunk and 'fnum' in chunk:\n",
    "                fname = 'part-{}'.format(chunk['fnum'])\n",
    "            else:\n",
    "                fname = 'part-{:05d}'.format(i)\n",
    "\n",
    "            for k in ['xray', 'sdss', 'ps', 'ls']:\n",
    "                try:\n",
    "                    chunk_data = chunk[k]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "                chunk_dst_path = os.path.join(data_path,\n",
    "                                              f'{fname}.{k}.gz_pkl')\n",
    "                chunk_data.to_pickle(chunk_dst_path, compression='gzip',\n",
    "                                     protocol=4)\n",
    "\n",
    "        with open(data_written_file, 'w'):\n",
    "            pass\n",
    "\n",
    "    chunks_files = defaultdict(dict)\n",
    "    for file in glob.glob(os.path.join(data_path, '*')):\n",
    "        parsed_filename = re.findall(r'^(.*)\\.(.*)\\.gz_pkl$',\n",
    "                                     os.path.basename(file))\n",
    "        print(parsed_filename)\n",
    "        if parsed_filename:\n",
    "            fname, chunk_type = parsed_filename[0]\n",
    "            chunks_files[fname][chunk_type] = file\n",
    "\n",
    "    for i, (fname, chunk) in tqdm.tqdm(enumerate(chunks_files.items()),\n",
    "                                       total=len(chunks_files)):\n",
    "        print(fname)\n",
    "        # chunk_number = re.findall(\"^part-(\\d*)$\", fname)\n",
    "        # print(chunk_number)\n",
    "        # if not len(chunk_number):\n",
    "        #     raise Exception(\"Wrong file name: {}\".format(fname))\n",
    "        # else:\n",
    "        #     chunk_number = int(chunk_number[0])\n",
    "        #     if chunk_number in [1]:\n",
    "        #         continue\n",
    "\n",
    "        dst_path = os.path.join(buf_path,\n",
    "                                f'{fname}.features.gz_pkl')  # TODO nice names format\n",
    "\n",
    "        if file_exists(dst_path):\n",
    "            files2predict.append(dst_path)\n",
    "            continue\n",
    "\n",
    "        catalog_kws_to_chunk_types = {\n",
    "            'xray_data_path': 'xray', 'sdss_path': 'sdss', 'ps_path': 'ps',\n",
    "            'ls_path': 'ls'\n",
    "        }\n",
    "        for kw, chunk_type in catalog_kws_to_chunk_types.items():\n",
    "            try:\n",
    "                catalog_kws[kw] = chunk[chunk_type]\n",
    "            except KeyError:\n",
    "                catalog_kws[kw] = None\n",
    "\n",
    "        if args.psFluxesPath:\n",
    "            ps_fluxes = pd.read_csv(args.psFluxesPath,\n",
    "                                    dtype={'objID': int})\n",
    "            ps_fluxes = {k: v for k, v in ps_fluxes.groupby(by='__file__')}\n",
    "            catalog_kws['ps_fluxes'] = ps_fluxes\n",
    "\n",
    "        catalog_kws['filename'] = fname\n",
    "        catalog = Catalog(**catalog_kws)\n",
    "        try:\n",
    "            status = catalog.prepare_data()\n",
    "        except Exception as e:\n",
    "            if str(e) == 'Found nothing in base catalog':\n",
    "                print(dst_path, fname)\n",
    "                shutil.copy(\n",
    "                    os.path.join(data_path, f'{fname}.xray.gz_pkl'),\n",
    "                    dst_path)\n",
    "                status = None\n",
    "            else:\n",
    "                print(e)\n",
    "                raise Exception(e)\n",
    "\n",
    "        if status == \"ps_manual\":\n",
    "            ps_objids.append(catalog.ps_objids)\n",
    "        # shutil.move(catalog.assembled_dataset_path, dst_path)\n",
    "        else:\n",
    "            files2predict.append(dst_path)\n",
    "else:\n",
    "    print('HEEEEEEEEEEEEEEY I am here')\n",
    "    for file in glob.glob(\n",
    "            os.path.join(args.predictOn, '*.features.gz_pkl')):\n",
    "        ### !!! Copying files\n",
    "        # shutil.copy(file, buf_path)\n",
    "        copyfile_link(file, buf_path)\n",
    "        files2predict.append(\n",
    "            os.path.join(buf_path, os.path.basename(file)))\n",
    "\n",
    "if ps_objids:\n",
    "    objids_csv_path = os.path.join(args.outputDir, 'ps_objids.csv')\n",
    "    pd.concat(ps_objids).to_csv(objids_csv_path, index=False)\n",
    "    print(\"\"\"\n",
    "    Now you are to download PanSTARRS fluxes from casjobs.\n",
    "    Upload generated csv and execute query with PanSTARRS_DR2 context:\n",
    "        select t.__file__, m.objid,\n",
    "        m.gPSFFlux, m.gPSFFluxErr, m.gKronFlux, m.gKronFluxErr,\n",
    "        m.rPSFFlux, m.rPSFFluxErr, m.rKronFlux, m.rKronFluxErr,\n",
    "        m.iPSFFlux, m.iPSFFluxErr, m.iKronFlux, m.iKronFluxErr,\n",
    "        m.zPSFFlux, m.zPSFFluxErr, m.zKronFlux, m.zKronFluxErr,\n",
    "        m.yPSFFlux, m.yPSFFluxErr, m.yKronFlux, m.yKronFluxErr\n",
    "\n",
    "        into MyDB.<destination table>\n",
    "        from MyDB.<table you created from csv> t\n",
    "        left join StackObjectAttributes m on m.objid=t.objid\n",
    "\n",
    "    Generated csv: {}\n",
    "    \"\"\".format(objids_csv_path))\n",
    "else:\n",
    "    if args.modelsIds is not None:\n",
    "        if args.customModels is not None:\n",
    "            with open(args.customModels, 'r') as fin:\n",
    "                custom_models_series = json.load(fin)\n",
    "\n",
    "            models_series = {**models_series, **custom_models_series}\n",
    "\n",
    "        print(models_series[args.modelsSeries])\n",
    "\n",
    "        models_path = models_series[args.modelsSeries]['path']\n",
    "        models = {f'{args.modelsSeries}{mid}': model for mid, model in\n",
    "                  models_series[args.modelsSeries]['models'].items()\n",
    "                  if int(mid) in args.modelsIds}\n",
    "        config = models_series[args.modelsSeries]['config']\n",
    "\n",
    "        files2predict = sorted(files2predict)\n",
    "        print(files2predict, models_path, models)\n",
    "\n",
    "        try:\n",
    "            use_wise_forced = config['use_wise_forced']\n",
    "        except KeyError:\n",
    "            use_wise_forced = False\n",
    "\n",
    "        print(format_message(\"Use WISE forced = \"), use_wise_forced, 'or', args.useWiseForced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7c4de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': '/data/SRGz/pzph1/models/x0', 'models': {19: 'psdr2+wise_deacls8tr_QSO+GALAXY-train_QSO_XbalancedGALAXY-sdss_unwise-wo_3XMM_XXLN_S82X_LH-w_VHzQs-v2-asinhmag_features', 21: 'psdr2+all_deacls8tr_QSO+GALAXY-train_QSO_XbalancedGALAXY-sdss_unwise-wo_3XMM_XXLN_S82X_LH-w_VHzQs-v2-asinhmag_features', 22: 'deacls8tr_QSO+GALAXY-train_QSO_XbalancedGALAXY-sdss_unwise-wo_3XMM_XXLN_S82X_LH-w_VHzQs-v2-asinhmag_features', 35: 'sdssdr16+psdr2+all_deacls8tr_QSO+GALAXY-train_QSO_XbalancedGALAXY-sdss_unwise-wo_3XMM_XXLN_S82X_LH-w_VHzQs-v2-asinhmag_features'}, 'config': {'perturb': 0, 'ebv_accounting': False, 'use_wise_forced': True}}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35724/555862972.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodels_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelsSeries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m models = {f'{args.modelsSeries}{mid}': model for mid, model in\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mmodels_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelsSeries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             if int(mid) in args.modelsIds}\n\u001b[1;32m     13\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelsSeries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35724/555862972.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m models = {f'{args.modelsSeries}{mid}': model for mid, model in\n\u001b[1;32m     11\u001b[0m             \u001b[0mmodels_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelsSeries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             if int(mid) in args.modelsIds}\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelsSeries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "if args.customModels is not None:\n",
    "    with open(args.customModels, 'r') as fin:\n",
    "        custom_models_series = json.load(fin)\n",
    "\n",
    "    models_series = {**models_series, **custom_models_series}\n",
    "\n",
    "print(models_series[args.modelsSeries])\n",
    "\n",
    "models_path = models_series[args.modelsSeries]['path']\n",
    "models = {f'{args.modelsSeries}{mid}': model for mid, model in\n",
    "            models_series[args.modelsSeries]['models'].items()\n",
    "            if int(mid) in args.modelsIds}\n",
    "config = models_series[args.modelsSeries]['config']\n",
    "\n",
    "files2predict = sorted(files2predict)\n",
    "print(files2predict, models_path, models)\n",
    "\n",
    "try:\n",
    "    use_wise_forced = config['use_wise_forced']\n",
    "except KeyError:\n",
    "    use_wise_forced = False\n",
    "\n",
    "print(format_message(\"Use WISE forced = \"), use_wise_forced, 'or', args.useWiseForced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8646b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "        predict(files2predict, models_path, models, config,\n",
    "                    wise_forced=use_wise_forced or args.useWiseForced,\n",
    "                    njobs=args.njobs, keep_in_memory=args.keepModelsInMemory,\n",
    "                    user_defined_features_transformation=user_defined_features_transformation)\n",
    "\n",
    "        assemble_and_analyze_results(buf_path, args.outputDir,\n",
    "                                     models_series=args.modelsSeries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
